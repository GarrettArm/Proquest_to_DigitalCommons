{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#! /usr/bin/env python3\n",
    "\n",
    "import os\n",
    "import csv\n",
    "\n",
    "from nameparser import HumanName\n",
    "from pymarc import MARCReader\n",
    "from titlecase import titlecase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "with open('source_data/MARCDATA.MRC', 'rb') as f:\n",
    "    reader = MARCReader(f)\n",
    "    all_records = list()\n",
    "    for record in reader:\n",
    "        all_records.append(record)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'fields': [{'001': 'AAI3167161'},\n",
       "  {'005': '20140908111943.5'},\n",
       "  {'008': '140908s2005    ||||||||||||||||| ||eng d'},\n",
       "  {'020': {'ind1': ' ', 'ind2': ' ', 'subfields': [{'a': '9780542025891'}]}},\n",
       "  {'035': {'ind1': ' ',\n",
       "    'ind2': ' ',\n",
       "    'subfields': [{'a': '(MiAaPQ)AAI3167161'}]}},\n",
       "  {'040': {'ind1': ' ',\n",
       "    'ind2': ' ',\n",
       "    'subfields': [{'a': 'MiAaPQ'}, {'c': 'MiAaPQ'}]}},\n",
       "  {'100': {'ind1': '1', 'ind2': ' ', 'subfields': [{'a': 'Song, In-hyouk.'}]}},\n",
       "  {'245': {'ind1': '1',\n",
       "    'ind2': '0',\n",
       "    'subfields': [{'a': 'Laterally movable gate field effect transistor (LMGFET) for microsensor and microactuator applications.'}]}},\n",
       "  {'300': {'ind1': ' ', 'ind2': ' ', 'subfields': [{'a': '171 p.'}]}},\n",
       "  {'500': {'ind1': ' ',\n",
       "    'ind2': ' ',\n",
       "    'subfields': [{'a': 'Source: Dissertation Abstracts International, Volume: 66-03, Section: B, page: 1638.'}]}},\n",
       "  {'500': {'ind1': ' ',\n",
       "    'ind2': ' ',\n",
       "    'subfields': [{'a': 'Director: Pratul K. Ajmera.'}]}},\n",
       "  {'502': {'ind1': ' ',\n",
       "    'ind2': ' ',\n",
       "    'subfields': [{'a': 'Thesis (Ph.D.)--Louisiana State University and Agricultural & Mechanical College, 2005.'}]}},\n",
       "  {'520': {'ind1': ' ',\n",
       "    'ind2': ' ',\n",
       "    'subfields': [{'a': 'Laterally Movable Gate Field Effect Transistor (LMGFET) invented at LSU as a microactuator is the subject of study in this research. The gate moving in lateral direction in a LMGFET changes channel width but keeps the channel length and the gap between the metal gate and the gate oxide constant. LMGFET offers linear change in drain current with gate motion and a large displacement range. This research is the first demonstration of LMGFET. In this dissertation, a post-IC LIGA-like process for LMGFET microstructure fabrication has been developed that is compatible with monolithic integration with CMOS circuitry.'}]}},\n",
       "  {'520': {'ind1': ' ',\n",
       "    'ind2': ' ',\n",
       "    'subfields': [{'a': 'A two-mask post-IC process has been developed in this research for LMGFET fabrication. This novel process utilizes S1813 photoresist as a sacrificial layer in conjunction with a thicker resist like AZ P4620 or SU-8 as an electroplating mold. New curing temperatures for the sacrificial layer photoresist have been determined for this purpose. LMGFET microstructures have been successfully integrated with CMOS circuitry on the same chip to form integrated microsystem.'}]}},\n",
       "  {'520': {'ind1': ' ',\n",
       "    'ind2': ' ',\n",
       "    'subfields': [{'a': 'LMGFET microstructure driven by a comb-drive with serpentine retaining spring shows sensitivities Sel of 2 and 1.43 nA/V respectively at 5 and 25 Hz. These numbers reflect that LMGFET is capable of measuring nm range displacement. Electrical characteristics of a depletion type LMGFET structure are measured and show an average sensitivity  Sl of -4 muA/mum at drain to source voltage VDS of 10 V with the gate shorted to source. Several applications of microsystems utilizing LMGFET microstructures as a position sensor or an accelerometer, a spectrum analyzer or an electro-mechanical filter and a mechanical/optical switch are described.'}]}},\n",
       "  {'590': {'ind1': ' ',\n",
       "    'ind2': ' ',\n",
       "    'subfields': [{'a': 'School code: 0107.'}]}},\n",
       "  {'650': {'ind1': ' ',\n",
       "    'ind2': '4',\n",
       "    'subfields': [{'a': 'Engineering, Electronics and Electrical.'}]}},\n",
       "  {'690': {'ind1': ' ', 'ind2': ' ', 'subfields': [{'a': '0544'}]}},\n",
       "  {'710': {'ind1': '2',\n",
       "    'ind2': '0',\n",
       "    'subfields': [{'a': 'Louisiana State University and Agricultural & Mechanical College.'}]}},\n",
       "  {'773': {'ind1': '0',\n",
       "    'ind2': ' ',\n",
       "    'subfields': [{'t': 'Dissertation Abstracts International'},\n",
       "     {'g': '66-03B.'}]}},\n",
       "  {'790': {'ind1': ' ', 'ind2': ' ', 'subfields': [{'a': '0107'}]}},\n",
       "  {'791': {'ind1': ' ', 'ind2': ' ', 'subfields': [{'a': 'Ph.D.'}]}},\n",
       "  {'792': {'ind1': ' ', 'ind2': ' ', 'subfields': [{'a': '2005'}]}},\n",
       "  {'793': {'ind1': ' ', 'ind2': ' ', 'subfields': [{'a': 'English'}]}},\n",
       "  {'856': {'ind1': ' ',\n",
       "    'ind2': ' ',\n",
       "    'subfields': [{'u': 'http://gateway.proquest.com/openurl?url_ver=Z39.88-2004&rft_val_fmt=info:ofi/fmt:kev:mtx:dissertation&res_dat=xri:pqm&rft_dat=xri:pqdiss:3167161'}]}}],\n",
       " 'leader': '02933nam a2200325   4500'}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# an example of one record\n",
    "all_records[1000].as_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def lookup_uid(record):\n",
    "    return record.get_fields('001')[0].value().replace('AAI','')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0000418'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lookup_uid(all_records[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# make a list of duplicated uids\n",
    "\n",
    "with open('source_data/DuplicatedInDigitalCommons.txt', 'r', encoding='utf-8') as f:\n",
    "    duplicate_uids = []\n",
    "    for line in f.readlines():\n",
    "        duplicate_uids.append(line.replace('.pdf', '').strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3049191\n",
      "3049223\n",
      "3051440\n",
      "3053695\n",
      "3053696\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "# make a list of restricted items\n",
    "# from the previously-made ranges\n",
    "# they match 1247 records from the marc file\n",
    "\n",
    "restricted_range_a = set(range(3048322, 3335145))\n",
    "restricted_range_b = {3021429, 3030348, 3451495}\n",
    "restricted_range_c = {3049191, 3049223, 3051440, 3053695, 3053696}\n",
    "restricted_range_d = set(range(3049188, 3329096))\n",
    "all_restricteds = set().union(restricted_range_a, \n",
    "                              restricted_range_b,\n",
    "                              restricted_range_c,\n",
    "                              restricted_range_d)\n",
    "all_restricteds.remove(3136164)\n",
    "\n",
    "restricted_uids = []\n",
    "\n",
    "for record in all_records:\n",
    "    uid = lookup_uid(record)\n",
    "    if uid in duplicate_uids:\n",
    "        continue\n",
    "    if int(uid) in all_restricteds:\n",
    "        print(lookup_uid(record))\n",
    "        \n",
    "print(len(restricted_uids))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# make a list of records not in duplicated or in restricted\n",
    "\n",
    "to_do_records = [i for i in all_records if lookup_uid(i) not in restricted_uids\n",
    "                                        and lookup_uid(i) not in duplicate_uids]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Testing things"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# test of all uids in marc file match a pdf on U drive\n",
    "# short answer: they all do\n",
    "\n",
    "# pdf_not_on_U = list()\n",
    "\n",
    "# for record in all_records:\n",
    "#     uid = lookup_uid(record)\n",
    "#     if os.path.isfile('/media/francis/U/ProquestDissertations/UnrestrictedTheses/{}.pdf'.format(uid)):\n",
    "#         continue\n",
    "#     pdf_not_on_U.append(uid)\n",
    "\n",
    "# print(pdf_not_on_U)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# show all unique values for field 650\n",
    "\n",
    "# all_650a = set()\n",
    "# for record in to_do_records:\n",
    "#     for i in record.get_fields('650'):\n",
    "#         all_650a.add(i.value())\n",
    "#     all_650a.add(record.get_fields('650')[0].value())\n",
    "# print(all_650a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# do any field values have an @ in it?\n",
    "\n",
    "# for record in to_do_records:\n",
    "#     all_fields = [i.value() for i in record.get_fields()]\n",
    "#     for text in all_fields:\n",
    "#         if '@' in text:\n",
    "#             print(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Making the crosswalk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def lookup_clean_title(record):\n",
    "    text = record.get_fields('245')[0].value()\n",
    "    text = titlecase(text)\n",
    "    text = text.replace(':  ', \": \")\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def make_dropbox_url(record):\n",
    "    uid = lookup_uid(record)\n",
    "    url = 'some.dropbox.url/public/something/{}.pdf'.format(uid)\n",
    "    return url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def interpret_directors(record):\n",
    "    text_a, text_b = parse_500(record)\n",
    "    return split_directors(text_b)\n",
    "\n",
    "def parse_500(record):\n",
    "    value_500 = [i.value() for i in record.get_fields('500')]\n",
    "    if len(value_500) == 1:\n",
    "        return value_500[0], ''\n",
    "    else:\n",
    "        return value_500[0], value_500[1]  \n",
    "\n",
    "def split_directors(text_b):\n",
    "    directors_list = parse_advisors_field(text_b)\n",
    "    if directors_list:\n",
    "        if len(directors_list) == 3:\n",
    "            return directors_list[0], directors_list[1], directors_list[2]\n",
    "        elif len(directors_list) == 2:\n",
    "            return directors_list[0], directors_list[1], ''\n",
    "        elif len(directors_list) == 1:\n",
    "            return directors_list[0], '', ''\n",
    "    return ('', '', '')\n",
    "\n",
    "def parse_advisors_field(text):\n",
    "    for title in ('Directors: ',\n",
    "                  'Director: ',\n",
    "                  'Co-Chairs: ',\n",
    "                  'Co-chairs: ',\n",
    "                  'Co-Chairmen: ',\n",
    "                  'Adviser: ',\n",
    "                  'Advisers: ',\n",
    "                  'Chair: ',\n",
    "                  'Directed: '):\n",
    "        if title in text:\n",
    "            text = text.replace(title, '')\n",
    "            text = text\n",
    "            text = remove_last_period_from_string(text)\n",
    "            if text:\n",
    "                return [i.strip() for i in text.split('; ')]\n",
    "    else:\n",
    "        return ''\n",
    "\n",
    "def remove_last_period_from_string(text):\n",
    "    if text[-1] == '.':\n",
    "        return text[:-1]\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# be sure to preserve order of items in field_520\n",
    "\n",
    "def combine_520(record):\n",
    "    list_520 = [i for i in record.get_fields('520')]\n",
    "    if list_520:\n",
    "        combined_text = ' '.join([i.value() for i in list_520])\n",
    "    else:\n",
    "        combined_text = ''\n",
    "    return combined_text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def combine_650(record):\n",
    "    value_650 = [i.value() for i in record.get_fields('650')]\n",
    "    value_650 = [i.capitalize().replace('.', '') for i in value_650]\n",
    "    if value_650:\n",
    "        combined_text = '; '.join(value_650)\n",
    "    else:\n",
    "        combined_text = ''\n",
    "    return combined_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def parse_author_names(record):\n",
    "    name_clump = record.get_fields('100')[0].value()\n",
    "    name_clump = remove_last_period_from_string(name_clump)\n",
    "    name = HumanName(name_clump)\n",
    "    last_name = name.last\n",
    "    middle_name = name.middle\n",
    "    suffix = name.suffix\n",
    "    suffix = standardize_suffix(suffix)\n",
    "    if name.nickname:\n",
    "        first_name = \"{} {}\".format(name.first, name.nickname)\n",
    "    else:\n",
    "        first_name = name.first\n",
    "    return first_name.capitalize(), middle_name.capitalize(), last_name.capitalize(), suffix\n",
    "\n",
    "def standardize_suffix(text):\n",
    "    replace_dict = {'JR': 'Jr', 'SR': 'Sr', '3RD': 'III', 'ED': 'Ed.'}\n",
    "    for wrong in replace_dict:\n",
    "        if wrong in text:\n",
    "            text = text.replace(wrong, replace_dict[wrong])\n",
    "    return text\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def lookup_inst(record):\n",
    "    text = record.get_fields('710')[0].value()\n",
    "    text = remove_last_period_from_string(text)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Making the csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def csv_writer(data, path):\n",
    "    with open(path, \"w\", newline='', encoding='utf-8') as csv_file:\n",
    "        writer = csv.writer(csv_file, delimiter=',', quotechar='\"', quoting=csv.QUOTE_ALL)\n",
    "        for line in data:\n",
    "            writer.writerow(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def build_csv(to_do_records):\n",
    "    csv_data = []\n",
    "    \n",
    "    csvfieldnames = ['urn',\n",
    "                     \"title\",\n",
    "                     \"fulltext_url\",\n",
    "                     'keywords',\n",
    "                     'abstract',\n",
    "                     \"author1_fname\",\n",
    "                     'author1_mname',\n",
    "                     'author1_lname',\n",
    "                     'author1_suffix',\n",
    "                     'author1_email',\n",
    "                     'author1_institution',\n",
    "                     'advisor1',\n",
    "                     'advisor2',\n",
    "                     'advisor3',\n",
    "                     'disciplines',\n",
    "                     'comments',\n",
    "                     'degree_name',\n",
    "                     'department',\n",
    "                     \"document_type\",\n",
    "                     'publication_date',\n",
    "                     'season',\n",
    "                     'release_date',\n",
    "\n",
    "                    ]\n",
    "    csv_data.append(csvfieldnames)\n",
    "\n",
    "    for record in to_do_records:\n",
    "        csv_urn = lookup_uid(record)\n",
    "        csv_title = lookup_clean_title(record)\n",
    "        fulltext_url = make_dropbox_url(record)\n",
    "        csv_keywords = combine_650(record)\n",
    "        csv_abstract = combine_520(record)\n",
    "        csv_first_name, csv_middle_name, csv_last_name, csv_suffix = parse_author_names(record)\n",
    "        csv_author_email = ''\n",
    "        csv_institution = lookup_inst(record)\n",
    "        csv_advisor1, csv_advisor2, cvs_advisor3 = interpret_directors(record)\n",
    "        csv_advisor3 = ''\n",
    "        csv_disciplines = ''\n",
    "        csv_comments = ''\n",
    "        csv_degree_name = record.get_fields('791')[0].value()\n",
    "        csv_department = ''\n",
    "        csv_document_type = 'Thesis'\n",
    "        csv_publication_date = record.get_fields('792')[0].value()\n",
    "        csv_season = ''\n",
    "        csv_release_date = ''\n",
    "\n",
    "\n",
    "        csv_data.append([csv_urn,\n",
    "                         csv_title,\n",
    "                         fulltext_url,\n",
    "                         csv_keywords,\n",
    "                         csv_abstract,\n",
    "                         csv_first_name,\n",
    "                         csv_middle_name,\n",
    "                         csv_last_name,\n",
    "                         csv_suffix,\n",
    "                         csv_author_email,\n",
    "                         csv_institution,\n",
    "                         csv_advisor1,\n",
    "                         csv_advisor2,\n",
    "                         csv_advisor3,\n",
    "                         csv_disciplines,\n",
    "                         csv_comments,\n",
    "                         csv_degree_name,\n",
    "                         csv_department,\n",
    "                         csv_document_type,\n",
    "                         csv_publication_date,\n",
    "                         csv_season,\n",
    "                         csv_release_date,\n",
    "                         \n",
    "                         ])\n",
    "    output_folder = '/home/francis/Desktop/lsu-git/Proquest_to_DigitalCommons/output'\n",
    "    os.makedirs(output_folder, exist_ok=True)\n",
    "    csv_writer(csv_data, '/home/francis/Desktop/lsu-git/Proquest_to_DigitalCommons/output/scrap_Proquest.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "build_csv(to_do_records)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# how many unique values for each field/subfield?\n",
    "\n",
    "# counting_items = dict()\n",
    "\n",
    "# def add_to_if_not_yet(k, v):\n",
    "#     v = v.strip()\n",
    "#     if v == \"None\" or not v or v == None:\n",
    "#         return\n",
    "#     if k in counting_items:\n",
    "#         counting_items[k].add(v)\n",
    "#     else:\n",
    "#         counting_items[k] = set()\n",
    "#         counting_items[k].add(v)\n",
    "\n",
    "# for record_as_marc in to_do_records:\n",
    "#     record = record_as_marc.as_dict()\n",
    "#     if not record['fields']:\n",
    "#         break\n",
    "#     for dictionary in record['fields']:\n",
    "#         for k, v in dictionary.items():\n",
    "#             if isinstance(v, str) and v:\n",
    "#                 add_to_if_not_yet(k, v)\n",
    "#             if isinstance(v, dict) and v:\n",
    "#                 ind1 = v['ind1']\n",
    "#                 fullpath = '{}/ind1'.format(k)\n",
    "#                 add_to_if_not_yet(fullpath, ind1)\n",
    "#                 ind2 = v['ind2']\n",
    "#                 fullpath = '{}/ind2'.format(k)\n",
    "#                 add_to_if_not_yet(fullpath, ind2)\n",
    "#                 subfields = v['subfields']\n",
    "#                 for subdictionary in subfields:\n",
    "#                     for x, y in subdictionary.items():\n",
    "#                         fullpath = '{}/subfields/{}'.format(k, x)\n",
    "#                         add_to_if_not_yet(fullpath, y)\n",
    "                        \n",
    "# for k, v in counting_items.items():\n",
    "#     print(k, len(v))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# how many unique values for each field/subfield?\n",
    "\n",
    "# keys_lengths = dict()\n",
    "\n",
    "# def add_to_if_not_yet(k, v):\n",
    "#     if k in keys_lengths:\n",
    "#         keys_lengths[k].add(v)\n",
    "#     else:\n",
    "#         keys_lengths[k] = set()\n",
    "#         keys_lengths[k].add(v)\n",
    "\n",
    "# for record_as_marc in to_do_records:\n",
    "#     record = record_as_marc.as_dict()\n",
    "#     if not record['fields']:\n",
    "#         break        \n",
    "#     field_keys = {k for field in record['fields'] for k in field.keys()}\n",
    "#     fields_list = [k for field in record['fields'] for k in field.keys()]\n",
    "#     for unique_field in field_keys:\n",
    "#         add_to_if_not_yet(unique_field, fields_list.count(unique_field))\n",
    "\n",
    "# print(keys_lengths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# this is supposed to check for broken utf-8, but i don't trust it's working\n",
    "\n",
    "# longest_field = 0\n",
    "\n",
    "# for record_as_marc in to_do_records:\n",
    "#     for field in record_as_marc.get_fields():\n",
    "#         value = field.value()\n",
    "#         try:\n",
    "#             bytes_value = value.encode()\n",
    "#             ascii_value = bytes_value.decode('ascii', \"strict\")\n",
    "#             if len(ascii_value) > longest_field:\n",
    "#                 longest_field = len(ascii_value)\n",
    "#                 print(record_as_marc)\n",
    "#         except:\n",
    "#             print(value)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# print a full record matching a specified uid\n",
    "\n",
    "# def find_print_record(uid):\n",
    "#     for record in all_records:\n",
    "#         if lookup_uid(record) == uid:\n",
    "#             return record.as_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
