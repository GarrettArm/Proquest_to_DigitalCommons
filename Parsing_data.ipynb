{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#! /usr/bin/env python3\n",
    "\n",
    "import os\n",
    "import csv\n",
    "\n",
    "from nameparser import HumanName\n",
    "from pymarc import MARCReader\n",
    "from titlecase import titlecase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "with open('source_data/MARCDATA.MRC', 'rb') as f:\n",
    "    reader = MARCReader(f)\n",
    "    all_records = list()\n",
    "    for record in reader:\n",
    "        all_records.append(record)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# make a list of duplicated uids\n",
    "\n",
    "with open('source_data/DuplicatedInDigitalCommons.txt', 'r', encoding='utf-8') as f:\n",
    "    duplicate_uids = []\n",
    "    for line in f.readlines():\n",
    "        duplicate_uids.append(line.replace('.pdf', '').strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def lookup_uid(record):\n",
    "    return record.get_fields('001')[0].value().replace('AAI','')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# make a list of restricted items\n",
    "# from the previously-made ranges\n",
    "# they match 1247 records from the marc file\n",
    "\n",
    "restricted_range_a = set(range(3048322, 3335145))\n",
    "restricted_range_b = {3021429, 3030348, 3451495}\n",
    "restricted_range_c = {3049191, 3049223, 3051440, 3053695, 3053696}\n",
    "restricted_range_d = set(range(3049188, 3329096))\n",
    "all_restricteds = set().union(restricted_range_a, \n",
    "                              restricted_range_b,\n",
    "                              restricted_range_c,\n",
    "                              restricted_range_d)\n",
    "all_restricteds.remove(3136164)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# identify restricted items\n",
    "\n",
    "restricted_uids = []\n",
    "\n",
    "for record in all_records:\n",
    "    uid = lookup_uid(record)\n",
    "    if uid in duplicate_uids:\n",
    "        continue\n",
    "    if int(uid) in all_restricteds:\n",
    "        print(lookup_uid(record))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# make a list of records not in duplicated or in restricted\n",
    "\n",
    "to_do_records = [i for i in all_records if lookup_uid(i) not in restricted_uids\n",
    "                                        and lookup_uid(i) not in duplicate_uids]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Making the crosswalk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def lookup_clean_title(record):\n",
    "    text = record.get_fields('245')[0].value()\n",
    "    text = titlecase(text)\n",
    "    text = text.replace(':  ', \": \")\n",
    "    for k, v in wrong_roman_numeral.items():\n",
    "        if k in text:\n",
    "            text = text.replace(k, v)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "wrong_roman_numeral = {' Ii': ' II',\n",
    "                       ' Iii ': ' III ',\n",
    "                       '-Iii': '-III',\n",
    "                       ' Iii.': ' III.',\n",
    "                       ' Iv ': ' IV ',\n",
    "                       ' Vi ': ' VI ',\n",
    "                       ' Iv.': ' IV.',\n",
    "                       ' Iv)': 'IV)',\n",
    "                       ' Viii': ' VIII',\n",
    "                       '-Vii ': '-VII',\n",
    "                       '-Viii': '-VIII',\n",
    "                       ' Vii': ' VII',\n",
    "                       }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def make_dropbox_url(record):\n",
    "    uid = lookup_uid(record)\n",
    "    url = 'some.dropbox.url/public/something/{}.pdf'.format(uid)\n",
    "    return url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def interpret_directors(record):\n",
    "    text_a, text_b = parse_500(record)\n",
    "    return split_directors(text_b)\n",
    "\n",
    "def parse_500(record):\n",
    "    value_500 = [i.value() for i in record.get_fields('500')]\n",
    "    if len(value_500) == 1:\n",
    "        return value_500[0], ''\n",
    "    else:\n",
    "        return value_500[0], value_500[1]  \n",
    "\n",
    "def split_directors(text_b):\n",
    "    directors_list = parse_advisors_field(text_b)\n",
    "    if directors_list:\n",
    "        if len(directors_list) == 3:\n",
    "            return directors_list[0], directors_list[1], directors_list[2]\n",
    "        elif len(directors_list) == 2:\n",
    "            return directors_list[0], directors_list[1], ''\n",
    "        elif len(directors_list) == 1:\n",
    "            return directors_list[0], '', ''\n",
    "    return ('', '', '')\n",
    "\n",
    "def parse_advisors_field(text):\n",
    "    for title in ('Directors: ',\n",
    "                  'Director: ',\n",
    "                  'Co-Chairs: ',\n",
    "                  'Co-chairs: ',\n",
    "                  'Co-Chairmen: ',\n",
    "                  'Adviser: ',\n",
    "                  'Advisers: ',\n",
    "                  'Chair: ',\n",
    "                  'Directed: '):\n",
    "        if title in text:\n",
    "            text = text.replace(title, '')\n",
    "            text = text\n",
    "            text = unperiod(text)\n",
    "            if text:\n",
    "                return [i.strip() for i in text.split('; ')]\n",
    "    else:\n",
    "        return ''\n",
    "\n",
    "def unperiod(text):\n",
    "    if text[-1] == '.':\n",
    "        return text[:-1]\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def find_source(record):\n",
    "    fields = [i.value() for i in record.get_fields('500') if 'Source' in i.value()][0]\n",
    "    fields = unperiod(fields)\n",
    "    fields = fields.replace('Source: ', '')\n",
    "    return fields"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def combine_520(record):\n",
    "    list_520 = [i for i in record.get_fields('520')]\n",
    "    if list_520:\n",
    "        combined_text = ' '.join([i.value() for i in list_520])\n",
    "    else:\n",
    "        combined_text = ''\n",
    "    return combined_text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def combine_650(record):\n",
    "    value_650 = [i.value() for i in record.get_fields('650')]\n",
    "    value_650 = [i.capitalize().replace('.', '') for i in value_650]\n",
    "    if value_650:\n",
    "        combined_text = '; '.join(value_650)\n",
    "    else:\n",
    "        combined_text = ''\n",
    "    return combined_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def parse_author_names(record):\n",
    "    name_clump = record.get_fields('100')[0].value()\n",
    "    name_clump = unperiod(name_clump)\n",
    "    name = HumanName(name_clump)\n",
    "    last_name = name.last\n",
    "    middle_name = name.middle\n",
    "    if \"Arch\" in last_name:\n",
    "        print(name_clump)\n",
    "        \n",
    "    suffix = name.suffix\n",
    "    suffix = standardize_suffix(suffix)\n",
    "    if name.nickname:\n",
    "        first_name = \"{} {}\".format(name.first, name.nickname)\n",
    "    else:\n",
    "        first_name = name.first\n",
    "    return first_name.capitalize(), middle_name.capitalize(), last_name.capitalize(), suffix\n",
    "\n",
    "def standardize_suffix(text):\n",
    "    replace_dict = {'JR': 'Jr', 'SR': 'Sr', '3RD': 'III', 'ED': 'Ed.'}\n",
    "    for wrong in replace_dict:\n",
    "        if wrong in text:\n",
    "            text = text.replace(wrong, replace_dict[wrong])\n",
    "    return text\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def lookup_inst(record):\n",
    "    text = record.get_fields('710')[0].value()\n",
    "    text = unperiod(text)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def lookup_isbn(record):\n",
    "    if record.get_fields('020'):\n",
    "        return record.get_fields('020')[0].value()\n",
    "    return ''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Making the csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def csv_writer(data, path):\n",
    "    with open(path, \"w\", newline='', encoding='utf-8') as csv_file:\n",
    "        writer = csv.writer(csv_file, delimiter=',', quotechar='\"', quoting=csv.QUOTE_ALL)\n",
    "        for line in data:\n",
    "            writer.writerow(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def build_csv(to_do_records):\n",
    "    csv_data = []\n",
    "    \n",
    "    csvfieldnames = ['urn',\n",
    "                     \"title\",\n",
    "                     \"fulltext_url\",\n",
    "                     'keywords',\n",
    "                     'abstract',\n",
    "                     \"author1_fname\",\n",
    "                     'author1_mname',\n",
    "                     'author1_lname',\n",
    "                     'author1_suffix',\n",
    "                     'author1_email',\n",
    "                     'author1_institution',\n",
    "                     'advisor1',\n",
    "                     'advisor2',\n",
    "                     'advisor3',\n",
    "                     'disciplines',\n",
    "                     'comments',\n",
    "                     'degree_name',\n",
    "                     'department',\n",
    "                     \"document_type\",\n",
    "                     'publication_date',\n",
    "                     'season',\n",
    "                     'release_date',\n",
    "                     'ISBN',\n",
    "                     'pagelength',\n",
    "                     'source',\n",
    "                     'diss_note',\n",
    "                     'host_item',\n",
    "                     'language',\n",
    "                     'host_url',\n",
    "                    ]\n",
    "    csv_data.append(csvfieldnames)\n",
    "\n",
    "    for record in to_do_records:\n",
    "        csv_urn = lookup_uid(record)\n",
    "        csv_title = lookup_clean_title(record)\n",
    "        fulltext_url = make_dropbox_url(record)\n",
    "        csv_keywords = combine_650(record)\n",
    "        csv_abstract = combine_520(record)\n",
    "        csv_first_name, csv_middle_name, csv_last_name, csv_suffix = parse_author_names(record)\n",
    "        csv_author_email = ''\n",
    "        csv_institution = lookup_inst(record)\n",
    "        csv_advisor1, csv_advisor2, cvs_advisor3 = interpret_directors(record)\n",
    "        csv_advisor3 = ''\n",
    "        csv_disciplines = ''\n",
    "        csv_comments = ''\n",
    "        csv_degree_name = record.get_fields('791')[0].value()\n",
    "        csv_department = ''\n",
    "        csv_document_type = 'Thesis'\n",
    "        csv_publication_date = record.get_fields('792')[0].value()\n",
    "        csv_season = ''\n",
    "        csv_release_date = ''\n",
    "        csv_isbn = lookup_isbn(record)\n",
    "        csv_pagelength = record.get_fields('300')[0].value().replace(' p.', '')\n",
    "        csv_source = find_source(record)\n",
    "        csv_diss_note = unperiod(record.get_fields('502')[0].value())\n",
    "        csv_host_item = unperiod(record.get_fields('773')[0].value())\n",
    "        csv_language = record.get_fields('793')[0].value()\n",
    "        csv_host_url = record.get_fields('856')[0].value()\n",
    "\n",
    "        csv_data.append([csv_urn,\n",
    "                         csv_title,\n",
    "                         fulltext_url,\n",
    "                         csv_keywords,\n",
    "                         csv_abstract,\n",
    "                         csv_first_name,\n",
    "                         csv_middle_name,\n",
    "                         csv_last_name,\n",
    "                         csv_suffix,\n",
    "                         csv_author_email,\n",
    "                         csv_institution,\n",
    "                         csv_advisor1,\n",
    "                         csv_advisor2,\n",
    "                         csv_advisor3,\n",
    "                         csv_disciplines,\n",
    "                         csv_comments,\n",
    "                         csv_degree_name,\n",
    "                         csv_department,\n",
    "                         csv_document_type,\n",
    "                         csv_publication_date,\n",
    "                         csv_season,\n",
    "                         csv_release_date,\n",
    "                         csv_isbn,\n",
    "                         csv_pagelength,\n",
    "                         csv_source,\n",
    "                         csv_diss_note,\n",
    "                         csv_host_item,\n",
    "                         csv_language,\n",
    "                         csv_host_url,\n",
    "                         ])\n",
    "    output_folder = '/home/francis/Desktop/lsu-git/Proquest_to_DigitalCommons/output'\n",
    "    os.makedirs(output_folder, exist_ok=True)\n",
    "    csv_writer(csv_data, '/home/francis/Desktop/lsu-git/Proquest_to_DigitalCommons/output/scrap_Proquest.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "build_csv(to_do_records)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Testing things"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# an example of one record\n",
    "# all_records[1000].as_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# show all unique values for field 650\n",
    "\n",
    "# all_650a = set()\n",
    "# for record in to_do_records:\n",
    "#     for i in record.get_fields('650'):\n",
    "#         all_650a.add(i.value())\n",
    "#     all_650a.add(record.get_fields('650')[0].value())\n",
    "# print(all_650a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# do any field values have an @ in it?\n",
    "\n",
    "# for record in to_do_records:\n",
    "#     all_fields = [i.value() for i in record.get_fields()]\n",
    "#     for text in all_fields:\n",
    "#         if '@' in text:\n",
    "#             print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# test of all uids in marc file match a pdf on U drive\n",
    "# short answer: they all do\n",
    "\n",
    "# pdf_not_on_U = list()\n",
    "\n",
    "# for record in all_records:\n",
    "#     uid = lookup_uid(record)\n",
    "#     if os.path.isfile('/media/francis/U/ProquestDissertations/UnrestrictedTheses/{}.pdf'.format(uid)):\n",
    "#         continue\n",
    "#     pdf_not_on_U.append(uid)\n",
    "\n",
    "# print(pdf_not_on_U)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# how many unique values for each field/subfield?\n",
    "\n",
    "# counting_items = dict()\n",
    "\n",
    "# def add_to_if_not_yet(k, v):\n",
    "#     v = v.strip()\n",
    "#     if v == \"None\" or not v or v == None:\n",
    "#         return\n",
    "#     if k in counting_items:\n",
    "#         counting_items[k].add(v)\n",
    "#     else:\n",
    "#         counting_items[k] = set()\n",
    "#         counting_items[k].add(v)\n",
    "\n",
    "# for record_as_marc in to_do_records:\n",
    "#     record = record_as_marc.as_dict()\n",
    "#     if not record['fields']:\n",
    "#         break\n",
    "#     for dictionary in record['fields']:\n",
    "#         for k, v in dictionary.items():\n",
    "#             if isinstance(v, str) and v:\n",
    "#                 add_to_if_not_yet(k, v)\n",
    "#             if isinstance(v, dict) and v:\n",
    "#                 ind1 = v['ind1']\n",
    "#                 fullpath = '{}/ind1'.format(k)\n",
    "#                 add_to_if_not_yet(fullpath, ind1)\n",
    "#                 ind2 = v['ind2']\n",
    "#                 fullpath = '{}/ind2'.format(k)\n",
    "#                 add_to_if_not_yet(fullpath, ind2)\n",
    "#                 subfields = v['subfields']\n",
    "#                 for subdictionary in subfields:\n",
    "#                     for x, y in subdictionary.items():\n",
    "#                         fullpath = '{}/subfields/{}'.format(k, x)\n",
    "#                         add_to_if_not_yet(fullpath, y)\n",
    "                        \n",
    "# for k, v in counting_items.items():\n",
    "#     print(k, len(v))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# how many unique values for each field/subfield?\n",
    "\n",
    "# keys_lengths = dict()\n",
    "# all_unique_keys = dict()\n",
    "\n",
    "# def add_to_if_not_yet(dictionary, k, v):\n",
    "#     if k in dictionary:\n",
    "#         dictionary[k].add(v)\n",
    "#     else:\n",
    "#         dictionary[k] = set()\n",
    "#         dictionary[k].add(v)\n",
    "\n",
    "# for record_as_marc in to_do_records:\n",
    "#     record = record_as_marc.as_dict()\n",
    "#     if not record['fields']:\n",
    "#         break        \n",
    "#     field_keys = {k for field in record['fields'] for k in field.keys()}\n",
    "#     fields_list = [k for field in record['fields'] for k in field.keys()]\n",
    "#     for unique_field in field_keys:\n",
    "#         add_to_if_not_yet(keys_lengths, unique_field, fields_list.count(unique_field))\n",
    "        \n",
    "# for record in to_do_records:\n",
    "#     for field in record.get_fields():\n",
    "#         add_to_if_not_yet(all_unique_keys, field.tag, field.value())\n",
    "\n",
    "# print('this (key) shows up {times} in a record:\\n', sorted(keys_lengths.items()))\n",
    "\n",
    "# print('\\nthis (key) has {unique values} across the repo:')\n",
    "# for k, v in sorted(all_unique_keys.items()):\n",
    "#     print(k, len(v))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# all_unique_keys['020']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# this is supposed to check for broken utf-8, but i don't trust it's working\n",
    "\n",
    "# longest_field = 0\n",
    "\n",
    "# for record_as_marc in to_do_records:\n",
    "#     for field in record_as_marc.get_fields():\n",
    "#         value = field.value()\n",
    "#         try:\n",
    "#             bytes_value = value.encode()\n",
    "#             ascii_value = bytes_value.decode('ascii', \"strict\")\n",
    "#             if len(ascii_value) > longest_field:\n",
    "#                 longest_field = len(ascii_value)\n",
    "#                 print(record_as_marc)\n",
    "#         except:\n",
    "#             print(value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# print a full record matching a specified uid\n",
    "\n",
    "def find_print_record(uid):\n",
    "    for record in all_records:\n",
    "        if lookup_uid(record) == uid:\n",
    "            return record.as_dict()\n",
    "        \n",
    "# find_print_record('9951617')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# find a record with a certain text in any value\n",
    "\n",
    "# for record in to_do_records:\n",
    "#     for field in record.get_fields():\n",
    "#         if 'Sethumadhava' in field.value():\n",
    "#             print(lookup_uid(record))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
