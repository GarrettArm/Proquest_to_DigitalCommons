{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#! /usr/bin/env python3\n",
    "\n",
    "import os\n",
    "import csv\n",
    "\n",
    "from nameparser import HumanName\n",
    "from pymarc import MARCReader\n",
    "from titlecase import titlecase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def lookup_uid(record):\n",
    "    return record.get_fields('001')[0].value().replace('AAI','')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "folder_on_U = '/media/francis/U/ProquestDissertations/Theses and Dissertations/ProquestDissertations/'\n",
    "\n",
    "with open(os.path.join(folder_on_U, 'UnrestrictedTheses', 'MARCDATA.MRC'), 'rb') as f:\n",
    "    reader = MARCReader(f)\n",
    "    marc_unrestricted_records = list()\n",
    "    for record in reader:\n",
    "        marc_unrestricted_records.append(record)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "with open(os.path.join(folder_on_U, 'RestrictedTheses', 'MARCDATA.MRC'), 'rb') as f:\n",
    "    reader = MARCReader(f)\n",
    "    marc_restricted_records = list()\n",
    "    for record in reader:\n",
    "        marc_restricted_records.append(record)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "images_path= '/media/francis/U/ProquestDissertations/Theses and Dissertations/Image Discs and Supplement Files'\n",
    "\n",
    "with open(os.path.join(images_path, 'MARCDATA.MRC'), 'rb') as f:\n",
    "    reader = MARCReader(f)\n",
    "    marc_images_records = list()\n",
    "    for record in reader:\n",
    "        marc_images_records.append(record)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "marc_all_records = {i for i in marc_restricted_records}.union({i for i in marc_unrestricted_records})\n",
    "\n",
    "marc_unrestricted_uids = {lookup_uid(i) for i in marc_unrestricted_records}\n",
    "marc_restricted_uids = {lookup_uid(i) for i in marc_restricted_records}\n",
    "marc_all_uids = {lookup_uid(record) for record in marc_all_records}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "folder_restricted = {file.replace('.pdf', '') \n",
    "                    for file in os.listdir(\n",
    "                        os.path.join(folder_on_U, 'RestrictedTheses'))\n",
    "                    if file.replace('.pdf', '').isnumeric()}\n",
    "folder_unrestricted = {file.replace('.pdf', '') \n",
    "                    for file in os.listdir(\n",
    "                        os.path.join(folder_on_U, 'UnrestrictedTheses'))\n",
    "                    if file.replace('.pdf', '').isnumeric()}\n",
    "folder_duplicated = {file.replace('.pdf', '') \n",
    "                    for file in os.listdir(\n",
    "                        os.path.join(folder_on_U, 'ETDDuplicates'))\n",
    "                    if file.replace('.pdf', '').isnumeric()}\n",
    "folder_images = {file.replace('.pdf', '') \n",
    "                    for file in os.listdir(images_path)\n",
    "                    if os.path.splitext(file)[1].lower() == '.pdf'}\n",
    "folder_all = folder_restricted.union(folder_unrestricted).union(folder_duplicated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "expected: pass 7308 pass 40 441\n",
      "observed: 8618 7308 1270 40 441\n"
     ]
    }
   ],
   "source": [
    "print('expected:', 'pass', len(marc_unrestricted_uids), 'pass', len(marc_restricted_uids), len(marc_images_records))\n",
    "print('observed:', len(folder_all), len(folder_unrestricted), len(folder_duplicated), len(folder_restricted), len(folder_images))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Making the crosswalk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def lookup_clean_title(record):\n",
    "    text = record.get_fields('245')[0].value()\n",
    "    text = titlecase(text)\n",
    "    text = text.replace(':  ', \": \")\n",
    "    for k, v in wrong_roman_numeral.items():\n",
    "        if k in text:\n",
    "            text = text.replace(k, v)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "wrong_roman_numeral = {' Ii': ' II',\n",
    "                       ' Iii ': ' III ',\n",
    "                       '-Iii': '-III',\n",
    "                       ' Iii.': ' III.',\n",
    "                       ' Iv ': ' IV ',\n",
    "                       ' Vi ': ' VI ',\n",
    "                       ' Iv.': ' IV.',\n",
    "                       ' Iv)': 'IV)',\n",
    "                       ' Viii': ' VIII',\n",
    "                       '-Vii ': '-VII',\n",
    "                       '-Viii': '-VIII',\n",
    "                       ' Vii': ' VII',\n",
    "                       }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def make_dropbox_url(record):\n",
    "    uid = lookup_uid(record)\n",
    "    if record in marc_restricted_records:\n",
    "        url = 'https://dl.dropboxusercontent.com/u/302551934/Proquests/Rs/{}.pdf'.format(uid)\n",
    "    elif record in marc_unrestricted_records:\n",
    "        url = 'https://dl.dropboxusercontent.com/u/302551934/Proquests/{}.pdf'.format(uid)        \n",
    "    return url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "abbr_degree = {\"MPT\": \"Master of Physical Therapy (MPT)\",\n",
    "    \"MUP\": \"Master of Urban Planning (MUP)\",\n",
    "    \"DM\": \"Doctor of Music (DM)\",\n",
    "    \"MTS\": \"Master of Theological Studies (MTS)\",\n",
    "    \"AuD\": \"Doctor of Audiology (AuD)\",\n",
    "    \"MSEE\": \"Master of Science in Electrical Engineering (MSEE)\",\n",
    "    \"MSIB\": \"Master of Science in International Business (MSIB)\",\n",
    "    \"MCSM\": \"Master of Construction Science and Management (MCSM)\",\n",
    "    \"PsyD\": \"Doctor of Psychology (PsyD)\",\n",
    "    \"MSEM\": \"Master of Science in Engineering Management (MSEM)\",\n",
    "    \"MSMSE\": \"Master of Science in Materials Science and Engineering (MSMSE)\",\n",
    "    \"RhD\": \"Doctor of Rehabilitation (RhD)\",\n",
    "    \"MATE\": \"Master of Arts in the Teaching of English (MATE)\",\n",
    "    \"DPT\": \"Doctor of Physical Therapy (DPT)\",\n",
    "    \"MSAgE\": \"Master of Science in Agricultural Engineering (MSAgE)\",\n",
    "    \"PhDOtol\": \"PhD Otolaryngology (PhDOtol)\",\n",
    "    \"MSHRM\": \"Master of Science in Human Resources Management (MSHRM)\",\n",
    "    \"MIM\": \"Master of International Management (MIM)\",\n",
    "    \"DMin\": \"Doctor of Ministry (DMin)\",\n",
    "    \"MSIE\": \"Master of Science in Industrial Engineering (MSIE)\",\n",
    "    \"MSISE\": \"Master of Science in Infrastructure Systems Engineering (MSISE)\",\n",
    "    \"DPA\": \"Doctor of Public Administration (DPA)\",\n",
    "    \"HSOP\": \"Doctor of Philosophy in Health Services Research (HSOP)\",\n",
    "    \"MMatSE\": \"Master of Materials Science and Engineering (MMatSE)\",\n",
    "    \"MAeroE\": \"Master of Aeronautical Engineering (MAeroE)\",\n",
    "    \"MMT\": \"Master in Management of Technology (MMT)\",\n",
    "    \"MSJ\": \"Master of Science in Jurisprudence (MSJ)\",\n",
    "    \"MHP\": \"Master of Historic Preservation (MHP)\",\n",
    "    \"DEng\": \"Doctor of Engineering (DEng)\",\n",
    "    \"MBA\": \"Master of Business Administration (MBA)\",\n",
    "    \"MRED\": \"Master of Real Estate Development (MRED)\",\n",
    "    \"MCTE\": \"Master of Career and Technology Education (MCTE)\",\n",
    "    \"MSAeroE\": \"Master of Science in Aerospace Engineering (MSAeroE)\",\n",
    "    \"MAR\": \"Master of Arts in Religion (MAR)\",\n",
    "    \"MST\": \"Master's of Science in Teaching (MST)\",\n",
    "    \"MJS\": \"Master of Judicial Studies (MJS)\",\n",
    "    \"MALA\": \"Master of Arts in Liberal Arts (MALA)\",\n",
    "    \"MSETM\": \"Master of Science in Environmental Technology Management (MSETM)\",\n",
    "    \"MSHTM\": \"Master of Science in Hospitality and Tourism Management (MSHTM)\",\n",
    "    \"Th.M\": \"Master of Theology (Th.M)\",\n",
    "    \"MSM\": \"Master of Science in Management (MSM)\",\n",
    "    \"MCRP\": \"Master of City and Regional Planning (MCRP)\",\n",
    "    \"MBS\": \"Master of Building Science (MBS)\",\n",
    "    \"MAIS\": \"Master of Arts in Interdisciplinary Studies (MAIS)\",\n",
    "    \"DBA\": \"Doctor of Business Administration (DBA)\",\n",
    "    \"MPH\": \"Master of Public Health (MPH)\",\n",
    "    \"MIDS\": \"Master of Interdisciplinary Studies (MIDS)\",\n",
    "    \"MPA/JD\": \"Master of Public Administration/Juris Doctorate (MPA/JD)\",\n",
    "    \"PhD\": \"Doctor of Philosophy (PhD)\",\n",
    "    \"DMgt\": \"Doctor of Management (DMgt)\",\n",
    "    \"MCIS\": \"Master of Computer and Information Science (MCIS)\",\n",
    "    \"MAE\": \"Master of Arts in Education (MAE)\",\n",
    "    \"MHD\": \"Master of Human Development (MHD)\",\n",
    "    \"MM\": \"Master of Music (MM)\",\n",
    "    \"MGS\": \"Master of General Studies (MGS)\",\n",
    "    \"MSN\": \"Master of Science in Nursing (MSN)\",\n",
    "    \"M.Div\": \"Master of Divinity (M.Div)\",\n",
    "    \"MAC\": \"Master of Arts in Counseling (MAC)\",\n",
    "    \"MCJ\": \"Master of Criminal Justice (MCJ)\",\n",
    "    \"MFR\": \"Master of Forest Resources (MFR)\",\n",
    "    \"MSSS\": \"Master of Science in Computer Science (MSCS)\",\n",
    "    \"MSA\": \"Master of Science in Administration (MSA)\",\n",
    "    \"MURP\": \"Master of Urban and Regional Planning (MURP)\",\n",
    "    \"MAS\": \"Master in Advanced Studies (MAS)\",\n",
    "    \"ND\": \"Doctor of Nursing (ND)\",\n",
    "    \"ME\": \"Master of Engineering (ME)\",\n",
    "    \"MSCRP\": \"Master of Science in Community and Regional Planning (MSCRP)\",\n",
    "    \"MArch\": \"Master of Architecture (MArch)\",\n",
    "    \"MLIS\": \"Master of Library and Information Science (MLIS)\",\n",
    "    \"MSOtol\": \"MS Otolaryngology (MSOtol)\",\n",
    "    \"MLS\": \"Master of Library Science/Master of Life Sciences (MLS)\",\n",
    "    \"MSMANFE\": \"Master of Science in Manufacturing Engineering (MSMANFE)\",\n",
    "    \"MSSE\": \"Master of Science and Software Engineering (MSSE)\",\n",
    "    \"MEngr\": \"Master of Engineering (MEngr)\",\n",
    "    \"MSB\": \"Masters of Science in Bioscience (MSB)\",\n",
    "    \"PED\": \"Doctor of Physical Education (PED)\",\n",
    "    \"MFA\": \"Master of Fine Arts (MFA)\",\n",
    "    \"MMC\": \"Master of Mass Communication (MMC)\",\n",
    "    \"MSBAE\": \"Master of Science in Biological and Agricultural Engineering (MSBAE)\",\n",
    "    \"MAgEd\": \"Master of Agricultural Education (MAgEd)\",\n",
    "    \"MSECE\": \"Master of Science in Electrical and Computer Engineering (MSECE)\",\n",
    "    \"DMD\": \"Doctor of Dental Medicine (DMD)\",\n",
    "    \"MSMatSE\": \"Master of Science in Material Science Engineering (MSMatSE)\",\n",
    "    \"MAPC\": \"Master of Arts in Pastoral Counseling (MAPC)\",\n",
    "    \"MSEd\": \"Master of Science in Education (MSEd)\",\n",
    "    \"DPDS\": \"Doctor of Planning and Development Studies (DPDS)\",\n",
    "    \"MRP\": \"Master of Regional Planning (MRP)\",\n",
    "    \"MNS\": \"Master of Natural Sciences (MNS)\",\n",
    "    \"EdD\": \"Doctor of Education (EdD)\",\n",
    "    \"DrPH\": \"Doctor of Public Health (DrPH)\",\n",
    "    \"DNS\": \"Doctor of Nursing Science (DNS)\",\n",
    "    \"MSIEOR\": \"Master of Science in Industrial Engineering and Operations Research (MSIEOR)\",\n",
    "    \"MAT\": \"Master of Arts in Teaching (MAT)\",\n",
    "    \"MEE\": \"Master of Electrical Engineering (MEE)\",\n",
    "    \"MS\": \"Master of Science (MS)\",\n",
    "    \"MSECO\": \"Master of Science in Economics (MSECO)\",\n",
    "    \"MLA\": \"Master of Landscape Architecture (MLA)\",\n",
    "    \"PhDSurg\": \"PhD Surgergy (PhDSurg)\",\n",
    "    \"MSES\": \"Master of Science in Engineering Science (MSES)\",\n",
    "    \"MHI\": \"Masters of Health Informatics (MHI)\",\n",
    "    \"MSME\": \"Master of Science in Mechanical Engineering (MSME)\",\n",
    "    \"MMUS\": \"Master of Music (MMUS)\",\n",
    "    \"MSW\": \"Master of Social Work (MSW)\",\n",
    "    \"MME\": \"Master of Music Education (MME)\",\n",
    "    \"DMA\": \"Doctor of Musical Arts (DMA)\",\n",
    "    \"MPA\": \"Master of Public Administration (MPA)\",\n",
    "    \"DA\": \"Doctor of Arts (DA)\",\n",
    "    \"MApStat\": \"Master of Applied Statistics (MApStat)\",\n",
    "    \"MSP\": \"Master of Science in Planning (MSP)\",\n",
    "    \"MPP\": \"Master of Public Policy (MPP)\",\n",
    "    \"MSExpSurg\": \"Medical Surgeon in Experimental Surgery (MSExpSurg)\",\n",
    "    \"EdS\": \"Education Specialist (EdS)\",\n",
    "    \"MF\": \"Master of Forestry (MF)\",\n",
    "    \"MPlan\": \"Master of Planning (MPlan)\",\n",
    "    \"MBT\": \"Master of Business Taxation (MBT)\",\n",
    "    \"HSD\": \"Doctor of Health and Safety (HSD)\",\n",
    "    \"MHRD\": \"Master of Human Resource Development (MHRD)\",\n",
    "    \"MSPH\": \"Master of Science in Public Health (MSPH)\",\n",
    "    \"MChE\": \"Master of Chemical Engineering (MChE)\",\n",
    "    \"MSPE\": \"Master of Science in Petroleum Engineering (MSPE)\",\n",
    "    \"MCompE\": \"Master of Computer Engineering (MCompE)\",\n",
    "    \"MT\": \"Master in Taxation (MT)\",\n",
    "    \"MAcc\": \"Master of Accounting (MAcc)\",\n",
    "    \"MPM\": \"Master of Public Management (MPM)\",\n",
    "    \"MSE\": \"Master of Science in Engineering (MSE)\",\n",
    "    \"DME\": \"Doctor of Music Education (DME)\",\n",
    "    \"DSW\": \"Doctor of Social Work (DSW)\",\n",
    "    \"MSCE\": \"Master of Science in Civil Engineering (MSCE)\",\n",
    "    \"DVM\": \"Doctor of Veterinary Medicine (DVM)\",\n",
    "    \"MCE\": \"Master of Civil Engineering (MCE)\",\n",
    "    \"MES\": \"Master of Environmental Studies (MES)\",\n",
    "    \"MECom\": \"Master of Electronic Commerce (MECom)\",\n",
    "    \"MHA\": \"Master of Health Administration (MHA)\",\n",
    "    \"PharmD\": \"Doctor of Pharmacy (PharmD)\",\n",
    "    \"MA\": \"Master of Arts (MA)\",\n",
    "    \"Ded\": \"Doctor of Education (Ded)\",\n",
    "    \"MEnvE\": \"Master of Environmental Engineering (MEnvE)\",\n",
    "    \"ReD\": \"Doctor of Recreation (ReD)\",\n",
    "    \"JD\": \"Juris Doctorate (JD)\",\n",
    "    \"MSBiosyAgE\": \"Master of Science in Biosystems and Agricultural Engineering (MSBiosyAgE)\",\n",
    "    \"PMBA\": \"Professional Master of Business Administration (PMBA)\",\n",
    "    \"MHAMS\": \"Master of Historical Administration and Museum Studies (MHAMS)\",\n",
    "    \"MSIS\": \"Master of Science in Interdisciplinary Studies (MSIS)\",\n",
    "    \"IMES\": \"International Master of Environmental Sciences (IMES)\",\n",
    "    \"MSChE\": \"Master of Science in Chemical Engineering (MSChE)\",\n",
    "    \"MPAcc\": \"Master of Professional Accounting (MPAcc)\",\n",
    "    \"MGIS\": \"Master of Geographic Information Science (MGIS)\",\n",
    "    \"MBioSci\": \"Master of Biological Science (MBioSci)\",\n",
    "    \"MCM\": \"Master of Construction Management (MCM)\",\n",
    "    \"MSMS\": \"Master of Science in Medical Sciences (MSMS)\",\n",
    "    \"MD\": \"Medical Doctor (MD)\",\n",
    "    \"Medical Science\": \"Doctor of Philosophy (Medical Science)\",\n",
    "    \"MGeoE\": \"Master of Geomechanics Engineering (MGeoE)\",\n",
    "    \"MEd\": \"Master of Education (MEd)\",\n",
    "    \"MAM\": \"Master in Agricultural Management (MAM)\",\n",
    "    \"MPRTM\": \"Master of Parks, Recreation and Tourism Management (MPRTM)\",\n",
    "    \"MAgr\": \"Master of Agriculture (MAgr)\",\n",
    "    \"POCS\": \"Doctor of Oceanography & Coastal Sciences (POCS)\",\n",
    "    \"PVMPB\": \"Doctor of Biomedical and Veterinary Medical Sciences-Pathobiological Sciences (PVMPB)\",\n",
    "    \"PNFS\": \"Doctor of Nutrition and Food Sciences (PNFS)\",\n",
    "    \"PENTM\": \"Doctor of Entomology (PENTM)\",\n",
    "    }\n",
    "\n",
    "\n",
    "\n",
    "# non_matching_degree_abbrevs = dict()\n",
    "# def expand_degree_type(degree_name):\n",
    "#     if degree_name in abbr_degree:\n",
    "#         return abbr_degree[degree_name]\n",
    "#     else:\n",
    "#         if degree_name not in non_matching_degree_abbrevs:\n",
    "#             non_matching_degree_abbrevs[degree_name] = []\n",
    "            \n",
    "# for record in ori:\n",
    "#     stated_degree = record.get_fields('791')[0].value()\n",
    "#     stated_degree = stated_degree.replace('.', '')\n",
    "#     if stated_degree in first_conversion:\n",
    "#         stated_degree = first_conversion[stated_degree]\n",
    "#     if stated_degree not in abbr_degree:\n",
    "#         print(lookup_uid(record))\n",
    "# #         print(stated_degree, record.get_fields('856')[0].value())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "first_conversion = {'EducatD': 'EdD',\n",
    "                    'DED': 'EdD',\n",
    "                    'DMus': 'DMA',\n",
    "                    'OCS': 'POCS',\n",
    "                    'VetMedSc': 'PVMPB',\n",
    "                    'DrSciEng': 'PNFS',\n",
    "                    'SCDC': 'PENTM'}\n",
    "\n",
    "def match_degrees(record):\n",
    "    stated_degree = record.get_fields('791')[0].value()\n",
    "    if not stated_degree:\n",
    "        return ''\n",
    "    alph_degree = stated_degree.replace('.','')\n",
    "    if alph_degree in first_conversion:\n",
    "        alph_degree = first_conversion[alph_degree]\n",
    "    if alph_degree in abbr_degree:\n",
    "        return abbr_degree[alph_degree]\n",
    "    else:\n",
    "        return 'not yet implemented'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def interpret_directors(record):\n",
    "    text_a, text_b = parse_500(record)\n",
    "    return split_directors(text_b)\n",
    "\n",
    "def parse_500(record):\n",
    "    value_500 = [i.value() for i in record.get_fields('500')]\n",
    "    if len(value_500) == 1:\n",
    "        return value_500[0], ''\n",
    "    else:\n",
    "        return value_500[0], value_500[1]  \n",
    "\n",
    "def split_directors(text_b):\n",
    "    directors_list = parse_advisors_field(text_b)\n",
    "    if directors_list:\n",
    "        if len(directors_list) == 3:\n",
    "            return directors_list[0], directors_list[1], directors_list[2]\n",
    "        elif len(directors_list) == 2:\n",
    "            return directors_list[0], directors_list[1], ''\n",
    "        elif len(directors_list) == 1:\n",
    "            return directors_list[0], '', ''\n",
    "    return ('', '', '')\n",
    "\n",
    "def parse_advisors_field(text):\n",
    "    for title in ('Directors: ',\n",
    "                  'Director: ',\n",
    "                  'Co-Chairs: ',\n",
    "                  'Co-chairs: ',\n",
    "                  'Co-Chairmen: ',\n",
    "                  'Adviser: ',\n",
    "                  'Advisers: ',\n",
    "                  'Chair: ',\n",
    "                  'Directed: '):\n",
    "        if title in text:\n",
    "            text = text.replace(title, '')\n",
    "            text = text\n",
    "            text = unperiod(text)\n",
    "            if text:\n",
    "                return [i.strip() for i in text.split('; ')]\n",
    "    else:\n",
    "        return ''\n",
    "\n",
    "def unperiod(text):\n",
    "    if text[-1] == '.':\n",
    "        return text[:-1]\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def find_source(record):\n",
    "    fields = [i.value() for i in record.get_fields('500') if 'Source' in i.value()][0]\n",
    "    fields = unperiod(fields)\n",
    "    fields = fields.replace('Source: ', '')\n",
    "    return fields"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def combine_520(record):\n",
    "    list_520 = [i for i in record.get_fields('520')]\n",
    "    if list_520:\n",
    "        combined_text = ' '.join([i.value() for i in list_520])\n",
    "    else:\n",
    "        combined_text = ''\n",
    "    return combined_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def combine_650(record):\n",
    "    value_650 = [i.value() for i in record.get_fields('650')]\n",
    "    value_650 = [i.capitalize().replace('.', '') for i in value_650]\n",
    "    if value_650:\n",
    "        combined_text = '; '.join(value_650)\n",
    "    else:\n",
    "        combined_text = ''\n",
    "    return combined_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def parse_author_names(record):\n",
    "    name_clump = record.get_fields('100')[0].value()\n",
    "    name_clump = unperiod(name_clump)\n",
    "    name = HumanName(name_clump)\n",
    "    last_name = name.last\n",
    "    middle_name = name.middle\n",
    "    suffix = name.suffix\n",
    "    suffix = standardize_suffix(suffix)\n",
    "    if name.nickname:\n",
    "        first_name = \"{} {}\".format(name.first, name.nickname)\n",
    "    else:\n",
    "        first_name = name.first\n",
    "    return first_name.capitalize(), middle_name.capitalize(), last_name.capitalize(), suffix\n",
    "\n",
    "def standardize_suffix(text):\n",
    "    replace_dict = {'JR': 'Jr', 'SR': 'Sr', '3RD': 'III', 'ED': 'Ed.'}\n",
    "    for wrong in replace_dict:\n",
    "        if wrong in text:\n",
    "            text = text.replace(wrong, replace_dict[wrong])\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def lookup_inst(record):\n",
    "    text = record.get_fields('710')[0].value()\n",
    "    text = unperiod(text)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def lookup_isbn(record):\n",
    "    if record.get_fields('020'):\n",
    "        return record.get_fields('020')[0].value()\n",
    "    return ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def determine_dtype(record):\n",
    "    for degree in ('PhD', 'DMA', 'EdD', 'DBA', 'PENTM', 'PNFS', 'PVMPB', 'POCS' ):\n",
    "        if degree in match_degrees(record):\n",
    "            return \"dissertation\"\n",
    "    return \"thesis\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def armageddon_if_restricted(record):\n",
    "    if record in marc_restricted_records:\n",
    "        return \"9999-12-01\"\n",
    "    return ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def is_restricted(record):\n",
    "    if record in marc_restricted_records:\n",
    "        return 'withheld'\n",
    "    return 'unrestricted'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Making the csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def csv_writer(data, path):\n",
    "    with open(path, \"w\", newline='', encoding='utf-8') as csv_file:\n",
    "        writer = csv.writer(csv_file, delimiter=',', quotechar='\"', quoting=csv.QUOTE_ALL)\n",
    "        for line in data:\n",
    "            writer.writerow(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def build_csv(records_list):\n",
    "    csv_data = []\n",
    "    \n",
    "    csvfieldnames = ['uid',\n",
    "                     \"title\",\n",
    "                     \"fulltext_url\",\n",
    "                     'keywords',\n",
    "                     'abstract',\n",
    "                     \"author1_fname\",\n",
    "                     'author1_mname',\n",
    "                     'author1_lname',\n",
    "                     'author1_suffix',\n",
    "                     'author1_email',\n",
    "                     'author1_institution',\n",
    "                     'advisor1',\n",
    "                     'advisor2',\n",
    "                     'advisor3',\n",
    "                     'availability',\n",
    "                     'availability_description',\n",
    "                     'disciplines',\n",
    "                     'comments',\n",
    "                     'degree_name',\n",
    "                     'department',\n",
    "                     \"document_type\",\n",
    "                     'embargo_date',\n",
    "                     'publication_date',\n",
    "                     'season',\n",
    "                     'release_date',\n",
    "                     'isbn',\n",
    "                     'pagelength',\n",
    "                     'source',\n",
    "                     'diss_note',\n",
    "                     'host_item',\n",
    "                     'language',\n",
    "                     'host_url',\n",
    "                    ]\n",
    "    csv_data.append(csvfieldnames)\n",
    "\n",
    "    for record in records_list:\n",
    "        csv_uid = lookup_uid(record)\n",
    "        csv_title = lookup_clean_title(record)\n",
    "        fulltext_url = make_dropbox_url(record)\n",
    "        csv_keywords = combine_650(record)\n",
    "        csv_abstract = combine_520(record)\n",
    "        csv_first_name, csv_middle_name, csv_last_name, csv_suffix = parse_author_names(record)\n",
    "        csv_author_email = ''\n",
    "        csv_institution = lookup_inst(record)\n",
    "        csv_advisor1, csv_advisor2, csv_advisor3 = interpret_directors(record)\n",
    "        csv_availability = is_restricted(record)\n",
    "        csv_avail_desc = ''\n",
    "        csv_disciplines = ''\n",
    "        csv_comments = ''\n",
    "        csv_degree_name = match_degrees(record)\n",
    "        csv_department = ''\n",
    "        csv_document_type = determine_dtype(record)\n",
    "        csv_embargo_date = armageddon_if_restricted(record)\n",
    "        csv_publication_date = record.get_fields('792')[0].value()\n",
    "        csv_season = ''\n",
    "        csv_release_date = ''\n",
    "        csv_isbn = lookup_isbn(record)\n",
    "        csv_pagelength = record.get_fields('300')[0].value().replace(' p.', '')\n",
    "        csv_source = find_source(record)\n",
    "        csv_diss_note = unperiod(record.get_fields('502')[0].value())\n",
    "        csv_host_item = unperiod(record.get_fields('773')[0].value())\n",
    "        csv_language = record.get_fields('793')[0].value()\n",
    "        csv_host_url = record.get_fields('856')[0].value()\n",
    "\n",
    "        csv_data.append([csv_uid,\n",
    "                         csv_title,\n",
    "                         fulltext_url,\n",
    "                         csv_keywords,\n",
    "                         csv_abstract,\n",
    "                         csv_first_name,\n",
    "                         csv_middle_name,\n",
    "                         csv_last_name,\n",
    "                         csv_suffix,\n",
    "                         csv_author_email,\n",
    "                         csv_institution,\n",
    "                         csv_advisor1,\n",
    "                         csv_advisor2,\n",
    "                         csv_advisor3,\n",
    "                         csv_availability,\n",
    "                         csv_avail_desc,\n",
    "                         csv_disciplines,\n",
    "                         csv_comments,\n",
    "                         csv_degree_name,\n",
    "                         csv_department,\n",
    "                         csv_document_type,\n",
    "                         csv_embargo_date,\n",
    "                         csv_publication_date,\n",
    "                         csv_season,\n",
    "                         csv_release_date,\n",
    "                         csv_isbn,\n",
    "                         csv_pagelength,\n",
    "                         csv_source,\n",
    "                         csv_diss_note,\n",
    "                         csv_host_item,\n",
    "                         csv_language,\n",
    "                         csv_host_url,\n",
    "                         ])\n",
    "    output_folder = '/home/francis/Desktop/lsu-git/Proquest_to_DigitalCommons/output'\n",
    "    os.makedirs(output_folder, exist_ok=True)\n",
    "    csv_writer(csv_data, '/home/francis/Desktop/lsu-git/Proquest_to_DigitalCommons/output/scrap_Proquest.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "build_csv(marc_unrestricted_records)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Testing things"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# an example of one record\n",
    "# orig_unrestricted_records[1000].as_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# show all unique values for field 650\n",
    "\n",
    "# all_650a = set()\n",
    "# for record in to_do_records:\n",
    "#     for i in record.get_fields('650'):\n",
    "#         all_650a.add(i.value())\n",
    "#     all_650a.add(record.get_fields('650')[0].value())\n",
    "# print(all_650a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# do any field values have an @ in it?\n",
    "\n",
    "# for record in to_do_records:\n",
    "#     all_fields = [i.value() for i in record.get_fields()]\n",
    "#     for text in all_fields:\n",
    "#         if '@' in text:\n",
    "#             print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# test of all uids in marc file match a pdf on U drive\n",
    "# short answer: they all do\n",
    "\n",
    "# pdf_not_on_U = list()\n",
    "\n",
    "# for record in orig_unrestricted_records:\n",
    "#     uid = lookup_uid(record)\n",
    "#     if os.path.isfile('/media/francis/U/ProquestDissertations/UnrestrictedTheses/{}.pdf'.format(uid)):\n",
    "#         continue\n",
    "#     pdf_not_on_U.append(uid)\n",
    "\n",
    "# print(pdf_not_on_U)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# how many unique values for each field/subfield?\n",
    "\n",
    "# counting_items = dict()\n",
    "\n",
    "# def add_to_if_not_yet(k, v):\n",
    "#     v = v.strip()\n",
    "#     if v == \"None\" or not v or v == None:\n",
    "#         return\n",
    "#     if k in counting_items:\n",
    "#         counting_items[k].add(v)\n",
    "#     else:\n",
    "#         counting_items[k] = set()\n",
    "#         counting_items[k].add(v)\n",
    "\n",
    "# for record_as_marc in to_do_records:\n",
    "#     record = record_as_marc.as_dict()\n",
    "#     if not record['fields']:\n",
    "#         break\n",
    "#     for dictionary in record['fields']:\n",
    "#         for k, v in dictionary.items():\n",
    "#             if isinstance(v, str) and v:\n",
    "#                 add_to_if_not_yet(k, v)\n",
    "#             if isinstance(v, dict) and v:\n",
    "#                 ind1 = v['ind1']\n",
    "#                 fullpath = '{}/ind1'.format(k)\n",
    "#                 add_to_if_not_yet(fullpath, ind1)\n",
    "#                 ind2 = v['ind2']\n",
    "#                 fullpath = '{}/ind2'.format(k)\n",
    "#                 add_to_if_not_yet(fullpath, ind2)\n",
    "#                 subfields = v['subfields']\n",
    "#                 for subdictionary in subfields:\n",
    "#                     for x, y in subdictionary.items():\n",
    "#                         fullpath = '{}/subfields/{}'.format(k, x)\n",
    "#                         add_to_if_not_yet(fullpath, y)\n",
    "                        \n",
    "# for k, v in counting_items.items():\n",
    "#     print(k, len(v))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# how many unique values for each field/subfield?\n",
    "\n",
    "# keys_lengths = dict()\n",
    "# all_unique_keys = dict()\n",
    "\n",
    "# def add_to_if_not_yet(dictionary, k, v):\n",
    "#     if k in dictionary:\n",
    "#         dictionary[k].add(v)\n",
    "#     else:\n",
    "#         dictionary[k] = set()\n",
    "#         dictionary[k].add(v)\n",
    "\n",
    "# for record_as_marc in to_do_records:\n",
    "#     record = record_as_marc.as_dict()\n",
    "#     if not record['fields']:\n",
    "#         break        \n",
    "#     field_keys = {k for field in record['fields'] for k in field.keys()}\n",
    "#     fields_list = [k for field in record['fields'] for k in field.keys()]\n",
    "#     for unique_field in field_keys:\n",
    "#         add_to_if_not_yet(keys_lengths, unique_field, fields_list.count(unique_field))\n",
    "        \n",
    "# for record in to_do_records:\n",
    "#     for field in record.get_fields():\n",
    "#         add_to_if_not_yet(all_unique_keys, field.tag, field.value())\n",
    "\n",
    "# print('this (key) shows up {times} in a record:\\n', sorted(keys_lengths.items()))\n",
    "\n",
    "# print('\\nthis (key) has {unique values} across the repo:')\n",
    "# for k, v in sorted(all_unique_keys.items()):\n",
    "#     print(k, len(v))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# all_unique_keys['020']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# this is supposed to check for broken utf-8, but i don't trust it's working\n",
    "\n",
    "# longest_field = 0\n",
    "\n",
    "# for record_as_marc in to_do_records:\n",
    "#     for field in record_as_marc.get_fields():\n",
    "#         value = field.value()\n",
    "#         try:\n",
    "#             bytes_value = value.encode()\n",
    "#             ascii_value = bytes_value.decode('ascii', \"strict\")\n",
    "#             if len(ascii_value) > longest_field:\n",
    "#                 longest_field = len(ascii_value)\n",
    "#                 print(record_as_marc)\n",
    "#         except:\n",
    "#             print(value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'fields': [{'001': 'AAI8811418'},\n",
       "  {'005': '20140908111618.5'},\n",
       "  {'008': '140908s1987    ||||||||||||||||| ||eng d'},\n",
       "  {'035': {'ind1': ' ',\n",
       "    'ind2': ' ',\n",
       "    'subfields': [{'a': '(MiAaPQ)AAI8811418'}]}},\n",
       "  {'040': {'ind1': ' ',\n",
       "    'ind2': ' ',\n",
       "    'subfields': [{'a': 'MiAaPQ'}, {'c': 'MiAaPQ'}]}},\n",
       "  {'100': {'ind1': '1', 'ind2': ' ', 'subfields': [{'a': 'Lee, Duc Hee.'}]}},\n",
       "  {'245': {'ind1': '1',\n",
       "    'ind2': '2',\n",
       "    'subfields': [{'a': 'A study of \"Suite No. 1, Seven Korean Folksongs for Violin (or Violoncello) and Piano\" (1958) by Min-jong Park.'}]}},\n",
       "  {'300': {'ind1': ' ', 'ind2': ' ', 'subfields': [{'a': '178 p.'}]}},\n",
       "  {'500': {'ind1': ' ',\n",
       "    'ind2': ' ',\n",
       "    'subfields': [{'a': 'Source: Dissertation Abstracts International, Volume: 49-07, Section: A, page: 1616.'}]}},\n",
       "  {'500': {'ind1': ' ',\n",
       "    'ind2': ' ',\n",
       "    'subfields': [{'a': 'Director: Thaddeus Brys.'}]}},\n",
       "  {'502': {'ind1': ' ',\n",
       "    'ind2': ' ',\n",
       "    'subfields': [{'a': 'Thesis (D.M.A.)--Louisiana State University and Agricultural & Mechanical College, 1987.'}]}},\n",
       "  {'520': {'ind1': ' ',\n",
       "    'ind2': ' ',\n",
       "    'subfields': [{'a': 'This monograph is a study of the Suite No. 1, 7 Korean Folksongs for Violin (or Violoncello) and Piano (1958) by Min-jong Park.'}]}},\n",
       "  {'520': {'ind1': ' ',\n",
       "    'ind2': ' ',\n",
       "    'subfields': [{'a': 'In 1958, the Korean composer and violinist Min-jong Park (b. 1918) composed the suite while he studied in Paris. This work, based on seven popular folksongs of Korea, combines Korean traditional folk material with Western compositional style. The melodies are basically adapted from the original folksongs but are highly embellished. The rhythm in the accompaniment generally follows the characteristic dance-like traditional rhythmic patterns of Korea, such as kutkori and semachi. The harmonic language used in the Suite No. 1 is based on the 19th century Western style, with a strong suggestion of French impressionistic harmony. The form of each song (or movement) is also in the traditional Western style, somewhat modified.'}]}},\n",
       "  {'520': {'ind1': ' ',\n",
       "    'ind2': ' ',\n",
       "    'subfields': [{'a': 'For background material this writer includes a short chronological survey of Korean music and six of the most popular traditional instruments of Korea with some detail. For a better understanding of the Suite No. 1 the writer also includes a description of the original folksongs according to scale, tonal center, range, interval content, cadence formula, meter, rhythmic pattern of the accompaniment, formal structure, and contour.'}]}},\n",
       "  {'520': {'ind1': ' ',\n",
       "    'ind2': ' ',\n",
       "    'subfields': [{'a': 'The Suite No. 1, which combines Eastern and Western musical elements, is highly recommended for the repertory of either violinist or cellist regardless of his or her nationality.'}]}},\n",
       "  {'590': {'ind1': ' ',\n",
       "    'ind2': ' ',\n",
       "    'subfields': [{'a': 'School code: 0107.'}]}},\n",
       "  {'650': {'ind1': ' ', 'ind2': '4', 'subfields': [{'a': 'Music.'}]}},\n",
       "  {'690': {'ind1': ' ', 'ind2': ' ', 'subfields': [{'a': '0413'}]}},\n",
       "  {'710': {'ind1': '2',\n",
       "    'ind2': '0',\n",
       "    'subfields': [{'a': 'Louisiana State University and Agricultural & Mechanical College.'}]}},\n",
       "  {'773': {'ind1': '0',\n",
       "    'ind2': ' ',\n",
       "    'subfields': [{'t': 'Dissertation Abstracts International'},\n",
       "     {'g': '49-07A.'}]}},\n",
       "  {'790': {'ind1': ' ', 'ind2': ' ', 'subfields': [{'a': '0107'}]}},\n",
       "  {'791': {'ind1': ' ', 'ind2': ' ', 'subfields': [{'a': 'D.M.A.'}]}},\n",
       "  {'792': {'ind1': ' ', 'ind2': ' ', 'subfields': [{'a': '1987'}]}},\n",
       "  {'793': {'ind1': ' ', 'ind2': ' ', 'subfields': [{'a': 'English'}]}},\n",
       "  {'856': {'ind1': ' ',\n",
       "    'ind2': ' ',\n",
       "    'subfields': [{'u': 'http://gateway.proquest.com/openurl?url_ver=Z39.88-2004&rft_val_fmt=info:ofi/fmt:kev:mtx:dissertation&res_dat=xri:pqm&rft_dat=xri:pqdiss:8811418'}]}}],\n",
       " 'leader': '02632nam a2200325   4500'}"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print a full record matching a specified uid\n",
    "\n",
    "def find_print_record(uid):\n",
    "    for record in marc_restricted_records:\n",
    "        if lookup_uid(record) == uid:\n",
    "            return record.as_dict()\n",
    "        \n",
    "find_print_record('8811418')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# find a record with a certain text in any value\n",
    "\n",
    "for record in marc_unrestricted_records:\n",
    "    for field in record.get_fields():\n",
    "        if 'Gipson' in field.value():\n",
    "            print(lookup_uid(record))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Editing MARC & moving pdfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# from pymarc import MARCWriter\n",
    "\n",
    "# trash_file = '/home/francis/Desktop/trash.marc'\n",
    "\n",
    "# # actual_restricted_records = [i for i in orig_restricted_records if lookup_uid(i) not in all_restricteds]\n",
    "# # actual_restricted_records.extend([i for i in orig_unrestricted_records if lookup_uid(i) in restricted_uids])\n",
    "\n",
    "# print(len(expected_unrestricted_records))\n",
    "\n",
    "\n",
    "# with open(trash_file, 'wb') as f:\n",
    "#     for record in expected_unrestricted_records:\n",
    "#         f.write(record.as_marc())\n",
    "    \n",
    "# with open(trash_file, 'rb') as f:\n",
    "#     reader = MARCReader(f)\n",
    "#     trash_records = list()\n",
    "#     for record in reader:\n",
    "#         trash_records.append(record)\n",
    "#     print(len(trash_records), len(expected_unrestricted_records))\n",
    "\n",
    "# print(expected_unrestricted_records[0].as_dict())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# import shutil\n",
    "\n",
    "# for uid in folder_duplicated:\n",
    "#     source = os.path.join(folder_on_U, 'UnrestrictedTheses', '{}.pdf'.format(uid))\n",
    "#     dest = os.path.join(folder_on_U, 'TitlesDuplicatedInETDDatbase', '{}.pdf'.format(uid))\n",
    "#     if os.path.isfile(source):\n",
    "#         print(source, '\\n', dest)\n",
    "#         shutil.move(source, dest)\n",
    "\n",
    "        \n",
    "# for uid in folder_true_restrict:\n",
    "#     source = os.path.join(folder_on_U, 'UnrestrictedTheses', '{}.pdf'.format(uid))\n",
    "#     dest = os.path.join(folder_on_U, 'RestrictedTheses', '{}.pdf'.format(uid))\n",
    "#     if os.path.isfile(source):\n",
    "#         print(source, '\\n', dest)\n",
    "#         shutil.move(source, dest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "set_a = set()\n",
    "for record in marc_unrestricted_records:\n",
    "    set_a.add(match_degrees(record)[-6:-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{' (DBA',\n",
       " ' (DMA',\n",
       " ' (EdD',\n",
       " ' (MMC',\n",
       " ' (PhD',\n",
       " '(PNFS',\n",
       " '(POCS',\n",
       " 'PENTM',\n",
       " 'PVMPB',\n",
       " 'e (MS'}"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set_a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DP69149: not found dupe\n",
      "DP69150: not found dupe\n",
      "DP69151: not found dupe\n",
      "DP69152: not found dupe\n",
      "DP69153: not found dupe\n",
      "DP69154: not found dupe\n",
      "DP69155: not found dupe\n",
      "DP69156: not found dupe\n",
      "DP69157: not found dupe\n",
      "DP69158: not found dupe\n",
      "DP69159: not found dupe\n",
      "DP69160: not found dupe\n",
      "DP69161: not found dupe\n",
      "DP69162: not found dupe\n",
      "DP69163: not found dupe\n",
      "DP69164: not found dupe\n",
      "DP69165: not found dupe\n",
      "DP69166: not found dupe\n",
      "DP69167: not found dupe\n",
      "DP69168: not found dupe\n",
      "DP69169: not found dupe\n",
      "DP69170: not found dupe\n",
      "DP69171: not found dupe\n",
      "DP69172: not found dupe\n",
      "DP69173: not found dupe\n",
      "DP69174: not found dupe\n",
      "DP69175: not found dupe\n",
      "DP69176: not found dupe\n",
      "DP69177: not found dupe\n",
      "DP69178: not found dupe\n",
      "DP69179: not found dupe\n",
      "DP69180: not found dupe\n",
      "DP69181: not found dupe\n",
      "DP69182: not found dupe\n",
      "DP69183: not found dupe\n",
      "DP69184: not found dupe\n",
      "DP69185: not found dupe\n",
      "DP69186: not found dupe\n",
      "DP69187: not found dupe\n",
      "DP69188: not found dupe\n",
      "DP69189: not found dupe\n",
      "DP69190: not found dupe\n",
      "DP69191: not found dupe\n",
      "DP69192: not found dupe\n",
      "DP69193: not found dupe\n",
      "DP69194: not found dupe\n",
      "DP69195: not found dupe\n",
      "DP69196: not found dupe\n",
      "DP69197: not found dupe\n",
      "DP69198: not found dupe\n",
      "DP69199: not found dupe\n",
      "DP69200: not found dupe\n",
      "DP69201: not found dupe\n",
      "DP69202: not found dupe\n",
      "DP69203: not found dupe\n",
      "DP69204: not found dupe\n",
      "DP69205: not found dupe\n",
      "DP69206: not found dupe\n",
      "DP69207: not found dupe\n",
      "DP69208: not found dupe\n",
      "DP69209: not found dupe\n",
      "DP69210: not found dupe\n",
      "DP69211: not found dupe\n",
      "DP69212: not found dupe\n",
      "DP69213: not found dupe\n",
      "DP69214: not found dupe\n",
      "DP69215: not found dupe\n",
      "DP69216: not found dupe\n",
      "DP69217: not found dupe\n",
      "DP69218: not found dupe\n",
      "DP69219: not found dupe\n",
      "DP69220: not found dupe\n",
      "DP69221: not found dupe\n",
      "DP69222: not found dupe\n",
      "DP69223: not found dupe\n",
      "DP69224: not found dupe\n",
      "DP69225: not found dupe\n",
      "DP69226: not found dupe\n",
      "DP69227: not found dupe\n",
      "DP69228: not found dupe\n",
      "DP69229: not found dupe\n",
      "DP69230: not found dupe\n",
      "DP69231: not found dupe\n",
      "DP69232: not found dupe\n",
      "DP69233: not found dupe\n",
      "DP69234: not found dupe\n",
      "DP69235: not found dupe\n",
      "DP69236: not found dupe\n",
      "DP69237: not found dupe\n",
      "DP69238: not found dupe\n",
      "DP69239: not found dupe\n",
      "DP69240: not found dupe\n",
      "DP69241: not found dupe\n",
      "DP69242: not found dupe\n",
      "DP69243: not found dupe\n",
      "DP69244: not found dupe\n",
      "DP69245: not found dupe\n",
      "DP69246: not found dupe\n",
      "DP69247: not found dupe\n",
      "DP69248: not found dupe\n",
      "DP69249: not found dupe\n",
      "DP69250: not found dupe\n",
      "DP69251: not found dupe\n",
      "DP69252: not found dupe\n",
      "DP69253: not found dupe\n",
      "DP69254: not found dupe\n",
      "DP69255: not found dupe\n",
      "DP69256: not found dupe\n",
      "DP69257: not found dupe\n",
      "DP69258: not found dupe\n",
      "DP69259: not found dupe\n",
      "DP69260: not found dupe\n",
      "DP69261: not found dupe\n",
      "DP69262: not found dupe\n",
      "DP69263: not found dupe\n",
      "DP69264: not found dupe\n",
      "DP69265: not found dupe\n",
      "DP69266: not found dupe\n",
      "DP69267: not found dupe\n",
      "DP69268: not found dupe\n",
      "DP69269: not found dupe\n",
      "DP69270: not found dupe\n",
      "DP69271: not found dupe\n",
      "DP69272: not found dupe\n",
      "DP69273: not found dupe\n",
      "DP69274: not found dupe\n",
      "DP69275: not found dupe\n",
      "DP69276: not found dupe\n",
      "DP69277: not found dupe\n",
      "DP69278: not found dupe\n",
      "DP69279: not found dupe\n",
      "DP69280: not found dupe\n",
      "DP69281: not found dupe\n",
      "DP69282: not found dupe\n",
      "DP69283: not found dupe\n",
      "DP69284: not found dupe\n",
      "DP69285: not found dupe\n",
      "DP69286: not found dupe\n",
      "DP69287: not found dupe\n",
      "DP69288: not found dupe\n",
      "DP69289: not found dupe\n",
      "DP69290: not found dupe\n",
      "DP69291: not found dupe\n",
      "DP69292: not found dupe\n",
      "DP69293: not found dupe\n",
      "DP69294: not found dupe\n",
      "DP69295: not found dupe\n",
      "DP69296: not found dupe\n",
      "DP69297: not found dupe\n",
      "DP69298: not found dupe\n",
      "DP69299: not found dupe\n",
      "DP69300: not found dupe\n",
      "DP69301: not found dupe\n",
      "DP69302: not found dupe\n",
      "DP69303: not found dupe\n",
      "DP69304: not found dupe\n",
      "DP69305: not found dupe\n",
      "DP69306: not found dupe\n",
      "DP69307: not found dupe\n",
      "DP69308: not found dupe\n",
      "DP69309: not found dupe\n",
      "DP69310: not found dupe\n",
      "DP69311: not found dupe\n",
      "DP69312: not found dupe\n",
      "DP69313: not found dupe\n",
      "DP69314: not found dupe\n",
      "DP69315: not found dupe\n",
      "DP69316: not found dupe\n",
      "DP69317: not found dupe\n",
      "DP69318: not found dupe\n",
      "DP69319: not found dupe\n",
      "DP69320: not found dupe\n",
      "DP69321: not found dupe\n",
      "DP69322: not found dupe\n",
      "DP69323: not found dupe\n",
      "DP69324: not found dupe\n",
      "DP69325: not found dupe\n",
      "DP69326: not found dupe\n",
      "DP69327: not found dupe\n",
      "DP69328: not found dupe\n",
      "DP69329: not found dupe\n",
      "DP69330: not found dupe\n",
      "DP69331: not found dupe\n",
      "DP69332: not found dupe\n",
      "DP69333: not found dupe\n",
      "DP69334: not found dupe\n",
      "DP69335: not found dupe\n",
      "DP69336: not found dupe\n",
      "DP69337: not found dupe\n",
      "DP69338: not found dupe\n",
      "DP69339: not found dupe\n",
      "DP69340: not found dupe\n",
      "DP69341: not found dupe\n",
      "DP69342: not found dupe\n",
      "DP69343: not found dupe\n",
      "DP69344: not found dupe\n",
      "DP69345: not found dupe\n",
      "DP69346: not found dupe\n",
      "DP69347: not found dupe\n",
      "DP69348: not found dupe\n",
      "DP69349: not found dupe\n",
      "DP69350: not found dupe\n",
      "DP69351: not found dupe\n",
      "DP69352: not found dupe\n",
      "DP69353: not found dupe\n",
      "DP69354: not found dupe\n",
      "DP69355: not found dupe\n",
      "DP69356: not found dupe\n",
      "DP69357: not found dupe\n",
      "DP69358: not found dupe\n",
      "DP69359: not found dupe\n",
      "DP69360: not found dupe\n",
      "DP69361: not found dupe\n",
      "DP69362: not found dupe\n",
      "DP69363: not found dupe\n",
      "DP69364: not found dupe\n",
      "DP69365: not found dupe\n",
      "DP69366: not found dupe\n",
      "DP69367: not found dupe\n",
      "DP69368: not found dupe\n",
      "DP69369: not found dupe\n",
      "DP69370: not found dupe\n",
      "DP69371: not found dupe\n",
      "DP69372: not found dupe\n",
      "DP69373: not found dupe\n",
      "DP69374: not found dupe\n",
      "DP69375: not found dupe\n",
      "DP69376: not found dupe\n",
      "DP69377: not found dupe\n",
      "DP69378: not found dupe\n",
      "DP69379: not found dupe\n",
      "DP69380: not found dupe\n",
      "DP69381: not found dupe\n",
      "DP69382: not found dupe\n",
      "DP69383: not found dupe\n",
      "DP69384: not found dupe\n",
      "DP69385: not found dupe\n",
      "DP69386: not found dupe\n",
      "DP69387: not found dupe\n",
      "DP69388: not found dupe\n",
      "DP69389: not found dupe\n",
      "DP69390: not found dupe\n",
      "DP69391: not found dupe\n",
      "DP69392: not found dupe\n",
      "DP69393: not found dupe\n",
      "DP69394: not found dupe\n",
      "DP69395: not found dupe\n",
      "DP69396: not found dupe\n",
      "DP69397: not found dupe\n",
      "DP69398: not found dupe\n",
      "DP69399: not found dupe\n",
      "DP69400: not found dupe\n",
      "DP69401: not found dupe\n",
      "DP69402: not found dupe\n",
      "DP69403: not found dupe\n",
      "DP69404: not found dupe\n",
      "DP69405: not found dupe\n",
      "DP69406: not found dupe\n",
      "DP69407: not found dupe\n",
      "DP69408: not found dupe\n",
      "DP69409: not found dupe\n",
      "DP69410: not found dupe\n",
      "DP69411: not found dupe\n",
      "DP69412: not found dupe\n",
      "DP69413: not found dupe\n",
      "DP69414: not found dupe\n",
      "DP69415: not found dupe\n",
      "DP69416: not found dupe\n",
      "DP69417: not found dupe\n",
      "DP69418: not found dupe\n",
      "DP69419: not found dupe\n",
      "DP69420: not found dupe\n",
      "DP69421: not found dupe\n",
      "DP69422: not found dupe\n",
      "DP69423: not found dupe\n",
      "DP69424: not found dupe\n",
      "DP69425: not found dupe\n",
      "DP69426: not found dupe\n",
      "DP69427: not found dupe\n",
      "DP69428: not found dupe\n",
      "DP69429: not found dupe\n",
      "DP69430: not found dupe\n",
      "DP69431: not found dupe\n",
      "DP69432: not found dupe\n",
      "DP69433: not found dupe\n",
      "DP69434: not found dupe\n",
      "DP69435: not found dupe\n",
      "DP69436: not found dupe\n",
      "DP69437: not found dupe\n",
      "DP69438: not found dupe\n",
      "DP69439: not found dupe\n",
      "DP69440: not found dupe\n",
      "DP69441: not found dupe\n",
      "DP69442: not found dupe\n",
      "DP69443: not found dupe\n",
      "DP69444: not found dupe\n",
      "DP69445: not found dupe\n",
      "DP69446: not found dupe\n",
      "DP69447: not found dupe\n",
      "DP69448: not found dupe\n",
      "DP69449: not found dupe\n",
      "DP69450: not found dupe\n",
      "DP69451: not found dupe\n",
      "DP69452: not found dupe\n",
      "DP69453: not found dupe\n",
      "DP69454: not found dupe\n",
      "DP69455: not found dupe\n",
      "DP69456: not found dupe\n",
      "DP69457: not found dupe\n",
      "DP69458: not found dupe\n",
      "DP69459: not found dupe\n",
      "DP69460: not found dupe\n",
      "DP69461: not found dupe\n",
      "DP69462: not found dupe\n",
      "DP69463: not found dupe\n",
      "DP69464: not found dupe\n",
      "DP69465: not found dupe\n",
      "DP69466: not found dupe\n",
      "DP69467: not found dupe\n",
      "DP69468: not found dupe\n",
      "DP69469: not found dupe\n",
      "DP69470: not found dupe\n",
      "DP69471: not found dupe\n",
      "DP69472: not found dupe\n",
      "DP69473: not found dupe\n",
      "DP69474: not found dupe\n",
      "DP69475: not found dupe\n",
      "DP69476: not found dupe\n",
      "DP69477: not found dupe\n",
      "DP69478: not found dupe\n",
      "DP69479: not found dupe\n",
      "DP69480: not found dupe\n",
      "DP69481: not found dupe\n",
      "DP69482: not found dupe\n",
      "DP69483: not found dupe\n",
      "DP69484: not found dupe\n",
      "DP69485: not found dupe\n",
      "DP69486: not found dupe\n",
      "DP69487: not found dupe\n",
      "DP69488: not found dupe\n",
      "DP69489: not found dupe\n",
      "DP69490: not found dupe\n",
      "DP69491: not found dupe\n",
      "DP69492: not found dupe\n",
      "DP69493: not found dupe\n",
      "DP69494: not found dupe\n",
      "DP69495: not found dupe\n",
      "DP69496: not found dupe\n",
      "DP69497: not found dupe\n",
      "DP69498: not found dupe\n",
      "DP69499: not found dupe\n",
      "DP69500: not found dupe\n",
      "DP69501: not found dupe\n",
      "DP69502: not found dupe\n",
      "DP69503: not found dupe\n",
      "DP69504: not found dupe\n",
      "DP69505: not found dupe\n",
      "DP69506: not found dupe\n",
      "DP69507: not found dupe\n",
      "DP69508: not found dupe\n",
      "DP69509: not found dupe\n",
      "DP69510: not found dupe\n",
      "DP69511: not found dupe\n",
      "DP69512: not found dupe\n",
      "DP69513: not found dupe\n",
      "DP69514: not found dupe\n",
      "DP69515: not found dupe\n",
      "DP69516: not found dupe\n",
      "DP69517: not found dupe\n",
      "DP69518: not found dupe\n",
      "DP69519: not found dupe\n",
      "DP69520: not found dupe\n",
      "DP69521: not found dupe\n",
      "DP69522: not found dupe\n",
      "DP69523: not found dupe\n",
      "DP69524: not found dupe\n",
      "DP69525: not found dupe\n",
      "DP69526: not found dupe\n",
      "DP69527: not found dupe\n",
      "DP69528: not found dupe\n",
      "DP69533: not found dupe\n",
      "DP69536: not found dupe\n",
      "DP69537: not found dupe\n",
      "DP69541: not found dupe\n",
      "DP69542: not found dupe\n",
      "DP69543: not found dupe\n",
      "DP69544: not found dupe\n",
      "DP69545: not found dupe\n",
      "DP69546: not found dupe\n",
      "DP69547: not found dupe\n",
      "DP69548: not found dupe\n",
      "DP69549: not found dupe\n",
      "DP69550: not found dupe\n",
      "DP69551: not found dupe\n",
      "DP69552: not found dupe\n",
      "DP69553: not found dupe\n",
      "DP69554: not found dupe\n",
      "DP69555: not found dupe\n",
      "DP69556: not found dupe\n",
      "DP69557: not found dupe\n",
      "DP69558: not found dupe\n",
      "EP69907: not found dupe\n",
      "EP69908: not found dupe\n",
      "EP69909: not found dupe\n",
      "EP69910: not found dupe\n",
      "EP69911: not found dupe\n",
      "EP69912: not found dupe\n",
      "EP69913: not found dupe\n",
      "EP69914: not found dupe\n",
      "EP69915: not found dupe\n",
      "EP69916: not found dupe\n",
      "EP69917: not found dupe\n",
      "EP69918: not found dupe\n",
      "EP69919: not found dupe\n",
      "EP69920: not found dupe\n",
      "EP69921: not found dupe\n",
      "EP69922: not found dupe\n",
      "EP69923: not found dupe\n",
      "EP69924: not found dupe\n",
      "EP69925: not found dupe\n",
      "EP69926: not found dupe\n",
      "EP69927: not found dupe\n",
      "EP69928: not found dupe\n",
      "EP69929: not found dupe\n",
      "EP69930: not found dupe\n",
      "EP69931: not found dupe\n",
      "EP69932: not found dupe\n",
      "EP69933: not found dupe\n",
      "EP69934: not found dupe\n",
      "EP69935: not found dupe\n",
      "EP69936: not found dupe\n",
      "EP69937: not found dupe\n",
      "EP69938: not found dupe\n",
      "EP69939: not found dupe\n",
      "EP69940: not found dupe\n",
      "EP69941: not found dupe\n",
      "EP69942: not found dupe\n",
      "EP69943: not found dupe\n",
      "EP69944: not found dupe\n",
      "EP69945: not found dupe\n",
      "EP69946: not found dupe\n"
     ]
    }
   ],
   "source": [
    "for item in marc_images_records:\n",
    "    uid = lookup_uid(item)\n",
    "    if uid in marc_unrestricted_uids:\n",
    "        print(\"{}: dupe in unrestricted\".format(uid))\n",
    "    if uid in marc_restricted_uids:\n",
    "        print(\"{}: dupe in restricted\".format(uid))\n",
    "    else:\n",
    "        print('{}: not found dupe'.format(uid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "leader 01210nam a2200301   4500\n",
      "fields [{'001': 'AAIDP69149'}, {'005': '20150728081845.5'}, {'008': '150728s1935    ||||||||||||||||| ||eng d'}, {'035': {'subfields': [{'a': '(MiAaPQ)AAIDP69149'}], 'ind1': ' ', 'ind2': ' '}}, {'040': {'subfields': [{'a': 'MiAaPQ'}, {'c': 'MiAaPQ'}], 'ind1': ' ', 'ind2': ' '}}, {'100': {'subfields': [{'a': 'Carter, Gipson Lafayette.'}], 'ind1': '1', 'ind2': ' '}}, {'245': {'subfields': [{'a': 'A survey of the status of Ramie.'}], 'ind1': '1', 'ind2': '2'}}, {'300': {'subfields': [{'a': '120 p.'}], 'ind1': ' ', 'ind2': ' '}}, {'500': {'subfields': [{'a': 'Source: Dissertation Abstracts International, Volume: 76-06(E), Section: B.'}], 'ind1': ' ', 'ind2': ' '}}, {'502': {'subfields': [{'a': 'Thesis (Ph.D.)--Louisiana State University and Agricultural & Mechanical College, 1935.'}], 'ind1': ' ', 'ind2': ' '}}, {'506': {'subfields': [{'a': 'This item must not be sold to any third party vendors.'}], 'ind1': ' ', 'ind2': ' '}}, {'506': {'subfields': [{'a': 'This item must not be added to any third party search indexes.'}], 'ind1': ' ', 'ind2': ' '}}, {'520': {'subfields': [{'a': 'Abstract not available.'}], 'ind1': ' ', 'ind2': ' '}}, {'590': {'subfields': [{'a': 'School code: 0107.'}], 'ind1': ' ', 'ind2': ' '}}, {'650': {'subfields': [{'a': 'Chemical engineering.'}], 'ind1': ' ', 'ind2': '4'}}, {'690': {'subfields': [{'a': '0542'}], 'ind1': ' ', 'ind2': ' '}}, {'710': {'subfields': [{'a': 'Louisiana State University and Agricultural & Mechanical College.'}, {'b': 'Chemical Engineering.'}], 'ind1': '2', 'ind2': '0'}}, {'773': {'subfields': [{'t': 'Dissertation Abstracts International'}, {'g': '76-06B(E).'}], 'ind1': '0', 'ind2': ' '}}, {'790': {'subfields': [{'a': '0107'}], 'ind1': ' ', 'ind2': ' '}}, {'791': {'subfields': [{'a': 'Ph.D.'}], 'ind1': ' ', 'ind2': ' '}}, {'792': {'subfields': [{'a': '1935'}], 'ind1': ' ', 'ind2': ' '}}, {'793': {'subfields': [{'a': 'English'}], 'ind1': ' ', 'ind2': ' '}}, {'856': {'subfields': [{'u': 'http://gateway.proquest.com/openurl?url_ver=Z39.88-2004&rft_val_fmt=info:ofi/fmt:kev:mtx:dissertation&res_dat=xri:pqm&rft_dat=xri:pqdiss:DP69149'}], 'ind1': ' ', 'ind2': ' '}}]\n"
     ]
    }
   ],
   "source": [
    "for item in marc_images_records:\n",
    "    for k,v in item.as_dict().items():\n",
    "        print(k, v)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
